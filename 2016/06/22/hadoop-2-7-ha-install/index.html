<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>hadoop 2.7 分布式安装 + HA | DIUDIU 小菜鸟</title><meta name="keywords" content="hadoop,ha,yarn,hdfs"><meta name="author" content="景帅"><meta name="copyright" content="景帅"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="hadoop 2.7 分布式安装 + HA 开始安装：  1、解压hadoop并修改环境变量（每台机器） [hadoop@new-cdh1 soft]$ tar -zvxf hadoop-2.6.0-cdh5.7.0.tar.gz [hadoop@new-cdh1 soft]$ vi ~&#x2F;.bash_profile # .bash_profile # Get the aliases and fun">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop 2.7 分布式安装 + HA">
<meta property="og:url" content="http://www.jsledd.cn/2016/06/22/hadoop-2-7-ha-install/">
<meta property="og:site_name" content="DIUDIU 小菜鸟">
<meta property="og:description" content="hadoop 2.7 分布式安装 + HA 开始安装：  1、解压hadoop并修改环境变量（每台机器） [hadoop@new-cdh1 soft]$ tar -zvxf hadoop-2.6.0-cdh5.7.0.tar.gz [hadoop@new-cdh1 soft]$ vi ~&#x2F;.bash_profile # .bash_profile # Get the aliases and fun">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.jsledd.cn/images/9.jpg">
<meta property="article:published_time" content="2016-06-22T10:50:32.000Z">
<meta property="article:modified_time" content="2021-01-20T07:55:39.691Z">
<meta property="article:author" content="景帅">
<meta property="article:tag" content="hadoop">
<meta property="article:tag" content="ha">
<meta property="article:tag" content="yarn">
<meta property="article:tag" content="hdfs">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.jsledd.cn/images/9.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.jsledd.cn/2016/06/22/hadoop-2-7-ha-install/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?97afb665c94e0e38fa62f5e1ea0c5c68";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 景帅","link":"链接: ","source":"来源: DIUDIU 小菜鸟","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-01-20 15:55:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">63</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">55</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><i class="fa-fw fas fa-robot - 机器学习"></i><span> 人工智能</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95"><i class="fa-fw fas fa-tags - 数组"></i><span> 数据结构与算法</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE"><i class="fa-fw fas fa-folder-open - hadoop"></i><span> 大数据</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93"><i class="fa-fw fas fa-folder-open - mongo"></i><span> 数据库</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80%E4%B8%8E%E6%8A%80%E5%B7%A7"><i class="fa-fw fas fa-folder-open - java"></i><span> 开发语言与技巧</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/games/"><i class="fa-fw fas fa-gamepad"></i><span> 游戏</span></a></li></ul></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/images/9.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">DIUDIU 小菜鸟</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><i class="fa-fw fas fa-robot - 机器学习"></i><span> 人工智能</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95"><i class="fa-fw fas fa-tags - 数组"></i><span> 数据结构与算法</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE"><i class="fa-fw fas fa-folder-open - hadoop"></i><span> 大数据</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93"><i class="fa-fw fas fa-folder-open - mongo"></i><span> 数据库</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80%E4%B8%8E%E6%8A%80%E5%B7%A7"><i class="fa-fw fas fa-folder-open - java"></i><span> 开发语言与技巧</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/games/"><i class="fa-fw fas fa-gamepad"></i><span> 游戏</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">hadoop 2.7 分布式安装 + HA</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2016-06-22T10:50:32.000Z" title="发表于 2016-06-22 18:50:32">2016-06-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-01-20T07:55:39.691Z" title="更新于 2021-01-20 15:55:39">2021-01-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/">hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>hadoop 2.7 分布式安装 + HA 开始安装：</p>
<h3 id="1-解压hadoop并修改环境变量每台机器"><a class="markdownIt-Anchor" href="#1-解压hadoop并修改环境变量每台机器"></a> 1、解压hadoop并修改环境变量（每台机器）</h3>
<p>[hadoop@new-cdh1 soft]$ tar -zvxf hadoop-2.6.0-cdh5.7.0.tar.gz<br />
[hadoop@new-cdh1 soft]$ vi ~/.bash_profile<br />
# .bash_profile</p>
<p># Get the aliases and functions<br />
if [ -f ~/.bashrc ]; then<br />
. ~/.bashrc<br />
fi</p>
<p># User specific environment and startup programs<br />
export HADOOP_HOME=/hadoop/soft/hadoop-2.6.0-cdh5.7.0<br />
PATH=<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mi>A</mi><mi>T</mi><mi>H</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">PATH:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span>HOME/bin:<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mi>A</mi><mi>D</mi><mi>O</mi><mi>O</mi><mi>P</mi><mi mathvariant="normal">_</mi><mi>H</mi><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi>b</mi><mi>i</mi><mi>n</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">HADOOP\_HOME/bin:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord">/</span><span class="mord mathdefault">b</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span>HADOOP_HOME/sbin</p>
<p>export PATH</p>
<p>[hadoop@new-cdh1 soft]$ source ~/.bash_profile</p>
<h3 id="2-修改hadoop_homeetchadoopslaves文件"><a class="markdownIt-Anchor" href="#2-修改hadoop_homeetchadoopslaves文件"></a> 2、修改$HADOOP_HOME/etc/hadoop/slaves文件</h3>
<p>[hadoop@new-cdh1 soft]$ vi hadoop-2.6.0-cdh5.7.0/etc/hadoop/slaves<br />
new-cdh15<br />
new-cdh16<br />
new-cdh5<br />
new-cdh6<br />
new-cdh7<br />
new-cdh9<br />
new-cdh10<br />
new-cdh11<br />
new-cdh12<br />
new-cdh13</p>
<h3 id="3-修改hadoop_homeetchadoophadoop-envsh和hadoop_homeetchadoopyarn-envsh文件"><a class="markdownIt-Anchor" href="#3-修改hadoop_homeetchadoophadoop-envsh和hadoop_homeetchadoopyarn-envsh文件"></a> 3、修改<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mi>A</mi><mi>D</mi><mi>O</mi><mi>O</mi><mi>P</mi><mi mathvariant="normal">_</mi><mi>H</mi><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi mathvariant="normal">/</mi><mi>h</mi><mi>a</mi><mi>d</mi><mi>o</mi><mi>o</mi><mi>p</mi><mi mathvariant="normal">/</mi><mi>h</mi><mi>a</mi><mi>d</mi><mi>o</mi><mi>o</mi><mi>p</mi><mo>−</mo><mi>e</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>h</mi><mi mathvariant="normal">和</mi></mrow><annotation encoding="application/x-tex">HADOOP\_HOME/etc/hadoop/hadoop-env.sh和</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord">/</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault">c</span><span class="mord">/</span><span class="mord mathdefault">h</span><span class="mord mathdefault">a</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span><span class="mord">/</span><span class="mord mathdefault">h</span><span class="mord mathdefault">a</span><span class="mord mathdefault">d</span><span class="mord mathdefault">o</span><span class="mord mathdefault">o</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord">.</span><span class="mord mathdefault">s</span><span class="mord mathdefault">h</span><span class="mord cjk_fallback">和</span></span></span></span>HADOOP_HOME/etc/hadoop/yarn-env.sh文件</h3>
<p>[hadoop@new-cdh1 soft]$ vi hadoop-2.6.0-cdh5.7.0/etc/hadoop/hadoop-env.sh<br />
…<br />
export JAVA_HOME=/opt/jdk1.7.0_79<br />
…</p>
<p>[hadoop@new-cdh1 soft]$ vi hadoop-2.6.0-cdh5.7.0/etc/hadoop/yarn-env.sh<br />
…<br />
export JAVA_HOME=/opt/jdk1.7.0_79<br />
…</p>
<h3 id="4-修改hadoophomeetchadoopcoresitexml文件"><a class="markdownIt-Anchor" href="#4-修改hadoophomeetchadoopcoresitexml文件"></a> 4、修改HADOOPHOME/etc/hadoop/core−site.xml文件</h3>
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://familyha</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/hadoop/tmp/hadoop-${user.name}</value>
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>1</value>
  </property>
  <property>
    <name>io.native.lib.available</name>
    <value>true</value>
  </property>
  <property>
    <name>io.compression.codecs</name> <value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec</value>
  </property>
  <property>
    <name>io.file.buffer.size</name>
    <value>131072</value>
  </property>
  <property> 
    <name>ha.zookeeper.quorum</name> 
    <value>new-cdh12:2181,new-cdh13:2181,new-cdh15:2181,new-cdh16:2181,new-cdh17:2181</value> 
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/hadoop/.ssh/id_rsa</value>
  </property>
</configuration>
<h3 id="5-修改hadoophomeetchadoopmapredsitexml文件"><a class="markdownIt-Anchor" href="#5-修改hadoophomeetchadoopmapredsitexml文件"></a> 5、修改HADOOPHOME/etc/hadoop/mapred−site.xml文件</h3>
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
\-\->

<!\-\- Put site-specific property overrides in this file. -->
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<property>
    <name>mapreduce.jobhistory.address</name>
    <value>new-cdh10:10020</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>new-cdh10:19888</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.webapp.https.address</name>
    <value>new-cdh10:19890</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.admin.address</name>
    <value>new-cdh10:10033</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.max-age-ms</name>
    <value>604800000</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.cleaner.interval</name>
    <value>86400000</value>
  </property>
  <property>
    <name>yarn.app.mapreduce.am.staging-dir</name>
    <value>/user</value>
  </property>
</configuration>
<h3 id="6-修改hadoop_homeetchadoophdfs-sitexml文件"><a class="markdownIt-Anchor" href="#6-修改hadoop_homeetchadoophdfs-sitexml文件"></a> 6、修改HADOOP_HOME/etc/hadoop/hdfs-site.xml文件</h3>
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
\-\->

<!\-\- Put site-specific property overrides in this file. -->
<configuration>
	<property>
                <name>dfs.nameservices</name>
                <value>familyha</value>
        </property>
        <property>
                <name>dfs.ha.namenodes.familyha</name>
                <value>family1,family2</value>
        </property>
        <property>
                <name>dfs.namenode.rpc-address.familyha.family1</name>
                <value>new-cdh1:8020</value>
        </property>
        <property>
                <name>dfs.namenode.rpc-address.familyha.family2</name>
                <value>new-cdh2:8020</value>
        </property>
        <property>
                <name>dfs.namenode.http-address.familyha.family1</name>
                <value>new-cdh1:50070</value>
        </property>
        <property>
                <name>dfs.namenode.http-address.familyha.family2</name>
                <value>new-cdh2:50070</value>
        </property>
        <property>
                <name>dfs.namenode.servicerpc-address.familyha.family1</name>
                <value>new-cdh1:53333</value>
        </property>
        <property>
                <name>dfs.namenode.servicerpc-address.familyha.family2</name>
                <value>new-cdh2:53333</value>
        </property>
	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://new-cdh5:8485;new-cdh6:8485;new-cdh7:8485/familyha</value>
	</property>
	<property>
		<name>dfs.client.failover.proxy.provider.familyha</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	<property>
		<name>dfs.journalnode.edits.dir</name>
		<value>/hadoop/data/journal</value>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:/hadoop/data/dfs/name</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:/hadoop/data/dfs/data</value>
	</property>
	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.webhdfs.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.journalnode.http-address</name>
		<value>0.0.0.0:8480</value>
	</property>
	<property>
		<name>dfs.journalnode.rpc-address</name>
		<value>0.0.0.0:8485</value>
	</property>
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
</configuration>
<h3 id="7-修改hadoop_homeetchadoopyarn-sitexml文件"><a class="markdownIt-Anchor" href="#7-修改hadoop_homeetchadoopyarn-sitexml文件"></a> 7、修改HADOOP_HOME/etc/hadoop/yarn-site.xml文件</h3>
<?xml version="1.0"?>
<pre><code>&lt;!\-\- Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); you 
	may not use this file except in compliance with the License. You may obtain 
	a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless 
	required by applicable law or agreed to in writing, software distributed 
	under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES 
	OR CONDITIONS OF ANY KIND, either express or implied. See the License for 
	the specific language governing permissions and limitations under the License. 
	See accompanying LICENSE file. --&gt;
&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
		&lt;value&gt;rm1,rm2&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;
		&lt;value&gt;new-cdh3&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;
		&lt;value&gt;new-cdh4&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;
		&lt;value&gt;rm1&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.address.rm1&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm1&#125;:8032&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.scheduler.address.rm1&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm1&#125;:8030&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.webapp.https.address.rm1&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm1&#125;:8089&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm1&#125;:8088&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm1&#125;:8025&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.admin.address.rm1&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm1&#125;:8041&lt;/value&gt;
	&lt;/property&gt;

	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.address.rm2&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm2&#125;:8032&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.scheduler.address.rm2&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm2&#125;:8030&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.webapp.https.address.rm2&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm2&#125;:8089&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm2&#125;:8088&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm2&#125;:8025&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.admin.address.rm2&lt;/name&gt;
		&lt;value&gt;$&#123;yarn.resourcemanager.hostname.rm2&#125;:8041&lt;/value&gt;
	&lt;/property&gt;

	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.ha.automatic-failover.enabled&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;
		&lt;value&gt;/hadoop/data/yarn/local&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
		&lt;value&gt;/hadoop/data/yarn/log&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.client.failover-proxy-provider&lt;/name&gt;
		&lt;value&gt;org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.zk-state-store.address&lt;/name&gt;
		&lt;value&gt;new-cdh12:2181,new-cdh13:2181,new-cdh15:2181,new-cdh16:2181,new-cdh17:2181&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
		&lt;value&gt;new-cdh12:2181,new-cdh13:2181,new-cdh15:2181,new-cdh16:2181,new-cdh17:2181&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;
		&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
		&lt;value&gt;cluster&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
		&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.scheduler.fair.allocation.file&lt;/name&gt;
		&lt;value&gt;/hadoop/soft/hadoop-2.6.0-cdh5.7.0/etc/hadoop/fairscheduler.xml&lt;/value&gt;
	&lt;/property&gt;

&lt;/configuration&gt;
</code></pre>
<h3 id="8-添加hadoop_homeetchadoopfairschedulerxml文件"><a class="markdownIt-Anchor" href="#8-添加hadoop_homeetchadoopfairschedulerxml文件"></a> 8、添加$HADOOP_HOME/etc/hadoop/fairscheduler.xml文件</h3>
<?xml version="1.0"?>
<allocations>
         <queue name="news">
                 <minResources>1024 mb, 1 vcores </minResources>
                 <maxResources>1536 mb, 1 vcores </maxResources>
                 <maxRunningApps>5</maxRunningApps>
                 <minSharePreemptionTimeout>300</minSharePreemptionTimeout>
                 <weight>1.0</weight>
                 <aclSubmitApps>root,yarn,search,hdfs</aclSubmitApps>
         </queue>
         <queue name="crawler">
                 <minResources>1024 mb, 1 vcores</minResources>
                 <maxResources>1536 mb, 1 vcores</maxResources>
         </queue>
         <queue name="map">
                 <minResources>1024 mb, 1 vcores</minResources>
                 <maxResources>1536 mb, 1 vcores</maxResources>
         </queue>
</allocations>
<h3 id="9-创建相关文件夹"><a class="markdownIt-Anchor" href="#9-创建相关文件夹"></a> 9、创建相关文件夹</h3>
<p>在相关的机器上创建文件夹</p>
<p>mkdir -p /hadoop/data/journal;<br />
mkdir -p /hadoop/data/dfs/name;<br />
mkdir -p /hadoop/data/dfs/data;<br />
mkdir -p /hadoop/data/yarn/local;<br />
mkdir -p /hadoop/data/yarn/log</p>
<h3 id="10-复制集群到其他机器"><a class="markdownIt-Anchor" href="#10-复制集群到其他机器"></a> 10、复制集群到其他机器</h3>
<p>[hadoop@new-cdh1 soft]$ scp -r hadoop-2.6.0-cdh5.7.0 new-cdh2:~/soft/<br />
[hadoop@new-cdh1 soft]$ scp -r hadoop-2.6.0-cdh5.7.0 new-cdh3:~/soft/<br />
…<br />
…<br />
…</p>
<h3 id="11-修改new-cdh4配置文件"><a class="markdownIt-Anchor" href="#11-修改new-cdh4配置文件"></a> 11、修改new-cdh4配置文件</h3>
<pre><code>    &lt;property&gt;
            &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;
            &lt;value&gt;rm2&lt;/value&gt;
    &lt;/property&gt;
</code></pre>
<h3 id="12-第一次启动"><a class="markdownIt-Anchor" href="#12-第一次启动"></a> 12、第一次启动</h3>
<h3 id="1-启动zookeeper略"><a class="markdownIt-Anchor" href="#1-启动zookeeper略"></a> 1、启动<a href="http://www.jsledd.cn/zookeeper-3-4-5-install/">zookeeper</a>（略）</h3>
<h3 id="2-格式化zookeeper集群"><a class="markdownIt-Anchor" href="#2-格式化zookeeper集群"></a> 2、格式化ZooKeeper集群</h3>
<p>在new-cdh1 执行</p>
<p>[hadoop@new-cdh1 soft]$ hdfs zkfc -formatZK<br />
…<br />
…<br />
16/06/22 17:51:37 INFO zookeeper.ClientCnxn: Session establishment complete on server new-cdh15/192.168.36.15:2181, sessionid = 0xf5576a58dc00004, negotiated timeout = 5000<br />
16/06/22 17:51:37 INFO ha.ActiveStandbyElector: Session connected.<br />
16/06/22 17:51:37 INFO ha.ActiveStandbyElector: Successfully created /hadoop-ha/familyha in ZK.<br />
16/06/22 17:51:37 INFO zookeeper.ZooKeeper: Session: 0xf5576a58dc00004 closed<br />
16/06/22 17:51:37 INFO zookeeper.ClientCnxn: EventThread shut down</p>
<p>zookeeper 查看格式化效果</p>
<p>[hadoop@new-cdh12 ~]$ <a target="_blank" rel="noopener" href="http://zkCli.sh">zkCli.sh</a><br />
Connecting to localhost:2181<br />
[zk: localhost:2181(CONNECTED) 1] ls /hadoop-ha<br />
[familyha]</p>
<h3 id="3-启动journalnode进程"><a class="markdownIt-Anchor" href="#3-启动journalnode进程"></a> 3、启动journalnode进程</h3>
<p>在new-cdh5、new-cdh6、new-cdh7 上分别启动并查看</p>
<p>[hadoop@new-cdh5 ~]$ <a target="_blank" rel="noopener" href="http://hadoop-daemon.sh">hadoop-daemon.sh</a> start journalnode<br />
starting journalnode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-journalnode-new-cdh5.out<br />
[hadoop@new-cdh5 ~]$ jps<br />
3697 Jps<br />
3653 JournalNode</p>
<h3 id="4-格式化new-cdh1-上的-namenode"><a class="markdownIt-Anchor" href="#4-格式化new-cdh1-上的-namenode"></a> 4、格式化new-cdh1 上的 namenode</h3>
<p>[hadoop@new-cdh1 ~]$ hdfs namenode -format<br />
16/06/22 18:10:12 INFO namenode.NameNode: STARTUP_MSG:<br />
/************************************************************<br />
STARTUP_MSG: Starting NameNode<br />
STARTUP_MSG:   host = new-cdh1/192.168.36.1<br />
STARTUP_MSG:   args = [-format]<br />
STARTUP_MSG:   version = 2.6.0-cdh5.7.0<br />
…<br />
…<br />
…<br />
16/06/22 18:10:18 INFO namenode.FSImage: Allocated new BlockPoolId: BP-996370904-192.168.36.1-1466590218912<br />
16/06/22 18:10:19 INFO common.Storage: Storage directory /hadoop/data/dfs/name has been successfully formatted.<br />
16/06/22 18:10:19 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0<br />
16/06/22 18:10:19 INFO util.ExitUtil: Exiting with status 0<br />
16/06/22 18:10:19 INFO namenode.NameNode: SHUTDOWN_MSG:<br />
/************************************************************<br />
SHUTDOWN_MSG: Shutting down NameNode at new-cdh1/192.168.36.1<br />
************************************************************/</p>
<h3 id="5-启动并查看new-cdh1上的namenode"><a class="markdownIt-Anchor" href="#5-启动并查看new-cdh1上的namenode"></a> 5、启动并查看new-cdh1上的namenode</h3>
<p>[hadoop@new-cdh1 ~]$ <a target="_blank" rel="noopener" href="http://hadoop-daemon.sh">hadoop-daemon.sh</a> start namenode<br />
starting namenode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-new-cdh1.out<br />
[hadoop@new-cdh1 ~]$ jps<br />
5486 NameNode<br />
5577 Jps</p>
<h3 id="6-将刚才格式化的new-cdh1-上的-namenode信息同步到备用new-cdh2-的namenode"><a class="markdownIt-Anchor" href="#6-将刚才格式化的new-cdh1-上的-namenode信息同步到备用new-cdh2-的namenode"></a> 6、将刚才格式化的new-cdh1 上的 namenode信息同步到备用new-cdh2 的namenode</h3>
<h1 id="hadoopnew-cdh2-~-hdfs-namenode-bootstrapstandby160622-181756-info-namenodenamenode-startup_msgstartup_msg-starting-namenodestartup_msg-host-new-cdh2192168362startup_msg-args-bootstrapstandbystartup_msg-version-260-cdh570startup_msg-classpath"><a class="markdownIt-Anchor" href="#hadoopnew-cdh2-~-hdfs-namenode-bootstrapstandby160622-181756-info-namenodenamenode-startup_msgstartup_msg-starting-namenodestartup_msg-host-new-cdh2192168362startup_msg-args-bootstrapstandbystartup_msg-version-260-cdh570startup_msg-classpath"></a> [hadoop@new-cdh2 ~]$ hdfs namenode -bootstrapStandby<br />
16/06/22 18:17:56 INFO namenode.NameNode: STARTUP_MSG:<br />
/************************************************************<br />
STARTUP_MSG: Starting NameNode<br />
STARTUP_MSG:   host = new-cdh2/192.168.36.2<br />
STARTUP_MSG:   args = [-bootstrapStandby]<br />
STARTUP_MSG:   version = 2.6.0-cdh5.7.0<br />
STARTUP_MSG:   classpath =<br />
…<br />
…</h1>
<h1 id="about-to-bootstrap-standby-id-family2-fromnameservice-id-familyhaother-namenode-id-family1other-nns-http-address-httpnew-cdh150070other-nns-ipc-address-new-cdh119216836153333namespace-id-1800644275block-pool-id-bp-996370904-192168361-1466590218912cluster-id-cid-753f5b34-21e6-4305-9672-50607ce8d630layout-version-60isupgradefinalized-true"><a class="markdownIt-Anchor" href="#about-to-bootstrap-standby-id-family2-fromnameservice-id-familyhaother-namenode-id-family1other-nns-http-address-httpnew-cdh150070other-nns-ipc-address-new-cdh119216836153333namespace-id-1800644275block-pool-id-bp-996370904-192168361-1466590218912cluster-id-cid-753f5b34-21e6-4305-9672-50607ce8d630layout-version-60isupgradefinalized-true"></a> About to bootstrap Standby ID family2 from:<br />
Nameservice ID: familyha<br />
Other Namenode ID: family1<br />
Other NN’s HTTP address: <a target="_blank" rel="noopener" href="http://new-cdh1:50070">http://new-cdh1:50070</a><br />
Other NN’s IPC  address: new-cdh1/192.168.36.1:53333<br />
Namespace ID: 1800644275<br />
Block pool ID: BP-996370904-192.168.36.1-1466590218912<br />
Cluster ID: CID-753f5b34-21e6-4305-9672-50607ce8d630<br />
Layout version: -60<br />
isUpgradeFinalized: true</h1>
<p>16/06/22 18:17:58 INFO common.Storage: Storage directory /hadoop/data/dfs/name has been successfully formatted.<br />
16/06/22 18:17:59 INFO namenode.TransferFsImage: Opening connection to <a target="_blank" rel="noopener" href="http://new-cdh1:50070/imagetransfer?getimage=1&amp;txid=0&amp;storageInfo=-60:1800644275:0:CID-753f5b34-21e6-4305-9672-50607ce8d630&amp;bootstrapstandby=true">http://new-cdh1:50070/imagetransfer?getimage=1&amp;txid=0&amp;storageInfo=-60:1800644275:0:CID-753f5b34-21e6-4305-9672-50607ce8d630&amp;bootstrapstandby=true</a><br />
16/06/22 18:17:59 INFO namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds<br />
16/06/22 18:17:59 INFO namenode.TransferFsImage: Transfer took 0.05s at 0.00 KB/s<br />
16/06/22 18:17:59 INFO namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.<br />
16/06/22 18:17:59 INFO util.ExitUtil: Exiting with status 0<br />
16/06/22 18:17:59 INFO namenode.NameNode: SHUTDOWN_MSG:<br />
/************************************************************<br />
SHUTDOWN_MSG: Shutting down NameNode at new-cdh2/192.168.36.2<br />
************************************************************/</p>
<h3 id="7-启动并查看new-cdh2上的namenode"><a class="markdownIt-Anchor" href="#7-启动并查看new-cdh2上的namenode"></a> 7、启动并查看new-cdh2上的namenode</h3>
<p>[hadoop@new-cdh2 ~]$ <a target="_blank" rel="noopener" href="http://hadoop-daemon.sh">hadoop-daemon.sh</a> start namenode<br />
starting namenode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-new-cdh2.out<br />
[hadoop@new-cdh2 ~]$ jps<br />
4178 Jps<br />
4087 NameNode</p>
<h3 id="8-启动并查看所有datanode"><a class="markdownIt-Anchor" href="#8-启动并查看所有datanode"></a> 8、启动并查看所有datanode</h3>
<p>[hadoop@new-cdh2 ~]$ <a target="_blank" rel="noopener" href="http://hadoop-daemons.sh">hadoop-daemons.sh</a> start datanode<br />
new-cdh5: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh5.out<br />
new-cdh6: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh6.out<br />
new-cdh12: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh12.out<br />
new-cdh7: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh7.out<br />
new-cdh13: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh13.out<br />
new-cdh11: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh11.out<br />
new-cdh9: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh9.out<br />
new-cdh10: starting datanode, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-new-cdh10.out<br />
[hadoop@new-cdh5 ~]$ jps<br />
3766 DataNode<br />
3865 Jps<br />
3653 JournalNode</p>
<h3 id="9-在new-cdh3上启动并查看yarn"><a class="markdownIt-Anchor" href="#9-在new-cdh3上启动并查看yarn"></a> 9、在new-cdh3上启动并查看yarn</h3>
<p>[hadoop@new-cdh3 ~]$ <a target="_blank" rel="noopener" href="http://start-yarn.sh">start-yarn.sh</a><br />
starting yarn daemons<br />
starting resourcemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-resourcemanager-new-cdh3.out<br />
new-cdh13: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh13.out<br />
new-cdh6: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh6.out<br />
new-cdh7: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh7.out<br />
new-cdh12: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh12.out<br />
new-cdh5: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh5.out<br />
new-cdh10: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh10.out<br />
new-cdh11: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh11.out<br />
new-cdh9: starting nodemanager, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/yarn-hadoop-nodemanager-new-cdh9.out<br />
[hadoop@new-cdh3 ~]$ jps<br />
4016 ResourceManager<br />
4295 Jps</p>
<h3 id="9-在new-cdh1-new-cdh2上分别启动并查看zkfc"><a class="markdownIt-Anchor" href="#9-在new-cdh1-new-cdh2上分别启动并查看zkfc"></a> 9、在new-cdh1、new-cdh2上分别启动并查看zkfc</h3>
<p>[hadoop@new-cdh2 ~]$ <a target="_blank" rel="noopener" href="http://hadoop-daemon.sh">hadoop-daemon.sh</a> start zkfc<br />
starting zkfc, logging to /hadoop/soft/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-zkfc-new-cdh2.out<br />
[hadoop@new-cdh2 ~]$ jps<br />
4087 NameNode<br />
4407 DFSZKFailoverController<br />
4459 Jps</p>
<p>10、在网页查看安装效果 <img src="http://www.jsledd.cn/wp-content/uploads/2016/06/new-cdh1.png" alt="new-cdh1" /> <img src="http://www.jsledd.cn/wp-content/uploads/2016/06/new-cdh1datanode.png" alt="new-cdh1datanode" /> <img src="http://www.jsledd.cn/wp-content/uploads/2016/06/new-cdh2.png" alt="new-cdh2" /><img src="http://www.jsledd.cn/wp-content/uploads/2016/06/new-cdh3yarn.png" alt="new-cdh3yarn" /> 以后启动就可以在 hdfs 和 yarn 的主节点上直接运行 start-dfs.sh或start-yarn.sh来启动</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">景帅</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.jsledd.cn/2016/06/22/hadoop-2-7-ha-install/">http://www.jsledd.cn/2016/06/22/hadoop-2-7-ha-install/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.jsledd.cn" target="_blank">DIUDIU 小菜鸟</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a><a class="post-meta__tags" href="/tags/ha/">ha</a><a class="post-meta__tags" href="/tags/yarn/">yarn</a><a class="post-meta__tags" href="/tags/hdfs/">hdfs</a></div><div class="post_share"><div class="social-share" data-image="/images/9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2016/06/22/hbase-install/"><img class="prev-cover" src="/images/3.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">hbase 分布式安装</div></div></a></div><div class="next-post pull-right"><a href="/2016/06/22/kafka-install/"><img class="next-cover" src="/images/9.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">kafka 分布式安装</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2016/06/22/hadoop-cdh5-7-0/" title="hadoop 2.7 手动安装（cdh5.7.0）目录"><img class="cover" src="/images/7.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-06-22</div><div class="title">hadoop 2.7 手动安装（cdh5.7.0）目录</div></div></a></div><div><a href="/2016/06/23/yarn-memory-cpu-vcode/" title="YARN中内存资源和CPU资源配置"><img class="cover" src="/images/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-06-23</div><div class="title">YARN中内存资源和CPU资源配置</div></div></a></div><div><a href="/2016/06/23/spark1-6-e5-88-86-e5-b8-83-e5-bc-8f-e5-ae-89-e8-a3-85/" title="SPARK1.6 分布式安装"><img class="cover" src="/images/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-06-23</div><div class="title">SPARK1.6 分布式安装</div></div></a></div><div><a href="/2019/04/05/datasourcev2/" title="Spark SQL DataSource V2 学习入门 + 代码模板"><img class="cover" src="/images/6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-04-05</div><div class="title">Spark SQL DataSource V2 学习入门 + 代码模板</div></div></a></div><div><a href="/2019/04/01/sparksql24api/" title="SPARK SQL2.4 自学教程"><img class="cover" src="/images/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-04-01</div><div class="title">SPARK SQL2.4 自学教程</div></div></a></div><div><a href="/2016/06/22/hbase-install/" title="hbase 分布式安装"><img class="cover" src="/images/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-06-22</div><div class="title">hbase 分布式安装</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">景帅</div><div class="author-info__description">DIUDIU 小菜鸟 学习笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">63</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">55</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/shadowagnoy"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/shadowagnoy/" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:jingshuai@jsledd.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录成长</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%A7%A3%E5%8E%8Bhadoop%E5%B9%B6%E4%BF%AE%E6%94%B9%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E6%AF%8F%E5%8F%B0%E6%9C%BA%E5%99%A8"><span class="toc-number">1.</span> <span class="toc-text"> 1、解压hadoop并修改环境变量（每台机器）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BF%AE%E6%94%B9hadoop_homeetchadoopslaves%E6%96%87%E4%BB%B6"><span class="toc-number">2.</span> <span class="toc-text"> 2、修改$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;slaves文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%BF%AE%E6%94%B9hadoop_homeetchadoophadoop-envsh%E5%92%8Chadoop_homeetchadoopyarn-envsh%E6%96%87%E4%BB%B6"><span class="toc-number">3.</span> <span class="toc-text"> 3、修改HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;hadoop−env.sh和HADOOP\_HOME&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh和HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;hadoop−env.sh和HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;yarn-env.sh文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E4%BF%AE%E6%94%B9hadoophomeetchadoopcoresitexml%E6%96%87%E4%BB%B6"><span class="toc-number">4.</span> <span class="toc-text"> 4、修改HADOOPHOME&#x2F;etc&#x2F;hadoop&#x2F;core−site.xml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E4%BF%AE%E6%94%B9hadoophomeetchadoopmapredsitexml%E6%96%87%E4%BB%B6"><span class="toc-number">5.</span> <span class="toc-text"> 5、修改HADOOPHOME&#x2F;etc&#x2F;hadoop&#x2F;mapred−site.xml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E4%BF%AE%E6%94%B9hadoop_homeetchadoophdfs-sitexml%E6%96%87%E4%BB%B6"><span class="toc-number">6.</span> <span class="toc-text"> 6、修改HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E4%BF%AE%E6%94%B9hadoop_homeetchadoopyarn-sitexml%E6%96%87%E4%BB%B6"><span class="toc-number">7.</span> <span class="toc-text"> 7、修改HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E6%B7%BB%E5%8A%A0hadoop_homeetchadoopfairschedulerxml%E6%96%87%E4%BB%B6"><span class="toc-number">8.</span> <span class="toc-text"> 8、添加$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;fairscheduler.xml文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E5%88%9B%E5%BB%BA%E7%9B%B8%E5%85%B3%E6%96%87%E4%BB%B6%E5%A4%B9"><span class="toc-number">9.</span> <span class="toc-text"> 9、创建相关文件夹</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E5%A4%8D%E5%88%B6%E9%9B%86%E7%BE%A4%E5%88%B0%E5%85%B6%E4%BB%96%E6%9C%BA%E5%99%A8"><span class="toc-number">10.</span> <span class="toc-text"> 10、复制集群到其他机器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E4%BF%AE%E6%94%B9new-cdh4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">11.</span> <span class="toc-text"> 11、修改new-cdh4配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%AF%E5%8A%A8"><span class="toc-number">12.</span> <span class="toc-text"> 12、第一次启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%90%AF%E5%8A%A8zookeeper%E7%95%A5"><span class="toc-number">13.</span> <span class="toc-text"> 1、启动zookeeper（略）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A0%BC%E5%BC%8F%E5%8C%96zookeeper%E9%9B%86%E7%BE%A4"><span class="toc-number">14.</span> <span class="toc-text"> 2、格式化ZooKeeper集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%90%AF%E5%8A%A8journalnode%E8%BF%9B%E7%A8%8B"><span class="toc-number">15.</span> <span class="toc-text"> 3、启动journalnode进程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%A0%BC%E5%BC%8F%E5%8C%96new-cdh1-%E4%B8%8A%E7%9A%84-namenode"><span class="toc-number">16.</span> <span class="toc-text"> 4、格式化new-cdh1 上的 namenode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%90%AF%E5%8A%A8%E5%B9%B6%E6%9F%A5%E7%9C%8Bnew-cdh1%E4%B8%8A%E7%9A%84namenode"><span class="toc-number">17.</span> <span class="toc-text"> 5、启动并查看new-cdh1上的namenode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%B0%86%E5%88%9A%E6%89%8D%E6%A0%BC%E5%BC%8F%E5%8C%96%E7%9A%84new-cdh1-%E4%B8%8A%E7%9A%84-namenode%E4%BF%A1%E6%81%AF%E5%90%8C%E6%AD%A5%E5%88%B0%E5%A4%87%E7%94%A8new-cdh2-%E7%9A%84namenode"><span class="toc-number">18.</span> <span class="toc-text"> 6、将刚才格式化的new-cdh1 上的 namenode信息同步到备用new-cdh2 的namenode</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoopnew-cdh2-~-hdfs-namenode-bootstrapstandby160622-181756-info-namenodenamenode-startup_msgstartup_msg-starting-namenodestartup_msg-host-new-cdh2192168362startup_msg-args-bootstrapstandbystartup_msg-version-260-cdh570startup_msg-classpath"><span class="toc-number"></span> <span class="toc-text"> [hadoop@new-cdh2 ~]$ hdfs namenode -bootstrapStandby

16&#x2F;06&#x2F;22 18:17:56 INFO namenode.NameNode: STARTUP_MSG:

&#x2F;************************************************************

STARTUP_MSG: Starting NameNode

STARTUP_MSG:   host &#x3D; new-cdh2&#x2F;192.168.36.2

STARTUP_MSG:   args &#x3D; [-bootstrapStandby]

STARTUP_MSG:   version &#x3D; 2.6.0-cdh5.7.0

STARTUP_MSG:   classpath &#x3D;

…

…</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#about-to-bootstrap-standby-id-family2-fromnameservice-id-familyhaother-namenode-id-family1other-nns-http-address-httpnew-cdh150070other-nns-ipc-address-new-cdh119216836153333namespace-id-1800644275block-pool-id-bp-996370904-192168361-1466590218912cluster-id-cid-753f5b34-21e6-4305-9672-50607ce8d630layout-version-60isupgradefinalized-true"><span class="toc-number"></span> <span class="toc-text"> About to bootstrap Standby ID family2 from:

Nameservice ID: familyha

Other Namenode ID: family1

Other NN’s HTTP address: http:&#x2F;&#x2F;new-cdh1:50070

Other NN’s IPC  address: new-cdh1&#x2F;192.168.36.1:53333

Namespace ID: 1800644275

Block pool ID: BP-996370904-192.168.36.1-1466590218912

Cluster ID: CID-753f5b34-21e6-4305-9672-50607ce8d630

Layout version: -60

isUpgradeFinalized: true</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E5%90%AF%E5%8A%A8%E5%B9%B6%E6%9F%A5%E7%9C%8Bnew-cdh2%E4%B8%8A%E7%9A%84namenode"><span class="toc-number">1.</span> <span class="toc-text"> 7、启动并查看new-cdh2上的namenode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E5%90%AF%E5%8A%A8%E5%B9%B6%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89datanode"><span class="toc-number">2.</span> <span class="toc-text"> 8、启动并查看所有datanode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E5%9C%A8new-cdh3%E4%B8%8A%E5%90%AF%E5%8A%A8%E5%B9%B6%E6%9F%A5%E7%9C%8Byarn"><span class="toc-number">3.</span> <span class="toc-text"> 9、在new-cdh3上启动并查看yarn</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E5%9C%A8new-cdh1-new-cdh2%E4%B8%8A%E5%88%86%E5%88%AB%E5%90%AF%E5%8A%A8%E5%B9%B6%E6%9F%A5%E7%9C%8Bzkfc"><span class="toc-number">4.</span> <span class="toc-text"> 9、在new-cdh1、new-cdh2上分别启动并查看zkfc</span></a></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/01/05/largegroup/" title="较大分组的位置"><img src="/2021/01/05/largegroup/largegroup.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="较大分组的位置"/></a><div class="content"><a class="title" href="/2021/01/05/largegroup/" title="较大分组的位置">较大分组的位置</a><time datetime="2021-01-05T02:55:40.000Z" title="发表于 2021-01-05 10:55:40">2021-01-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2019/09/29/mongodb42-shard/" title="Mongodb4.2.0 副本集 + 分片 + 自动运维脚本"><img src="/images/11.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mongodb4.2.0 副本集 + 分片 + 自动运维脚本"/></a><div class="content"><a class="title" href="/2019/09/29/mongodb42-shard/" title="Mongodb4.2.0 副本集 + 分片 + 自动运维脚本">Mongodb4.2.0 副本集 + 分片 + 自动运维脚本</a><time datetime="2019-09-29T07:46:25.000Z" title="发表于 2019-09-29 15:46:25">2019-09-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2019/04/05/datasourcev2/" title="Spark SQL DataSource V2 学习入门 + 代码模板"><img src="/images/6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spark SQL DataSource V2 学习入门 + 代码模板"/></a><div class="content"><a class="title" href="/2019/04/05/datasourcev2/" title="Spark SQL DataSource V2 学习入门 + 代码模板">Spark SQL DataSource V2 学习入门 + 代码模板</a><time datetime="2019-04-05T08:09:19.000Z" title="发表于 2019-04-05 16:09:19">2019-04-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2019/04/01/sparksql24api/" title="SPARK SQL2.4 自学教程"><img src="/images/3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SPARK SQL2.4 自学教程"/></a><div class="content"><a class="title" href="/2019/04/01/sparksql24api/" title="SPARK SQL2.4 自学教程">SPARK SQL2.4 自学教程</a><time datetime="2019-04-01T07:46:25.000Z" title="发表于 2019-04-01 15:46:25">2019-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2018/08/05/linearregression/" title="线性回归模型的推导"><img src="/images/10.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="线性回归模型的推导"/></a><div class="content"><a class="title" href="/2018/08/05/linearregression/" title="线性回归模型的推导">线性回归模型的推导</a><time datetime="2018-08-05T02:40:11.000Z" title="发表于 2018-08-05 10:40:11">2018-08-05</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/images/9.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2021 By 景帅</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a rel="nofollow" target="_blank" href="http://www.miibeian.gov.cn/"><img class="icp-icon" src="/img/icp.png">京ICP备16021974号-1</a><br><span id="span_dt_dt"></span><script type="text/javascript">function s(){window.setTimeout("s()",1000);BirthDay=new Date("4/18/2016 12:48:26");today=new Date();timeold=(today.getTime()-BirthDay.getTime());sectimeold=timeold/1000;secondsold=Math.floor(sectimeold);msPerDay=24*60*60*1000;e_daysold=timeold/msPerDay;daysold=Math.floor(e_daysold);e_hrsold=(e_daysold-daysold)*24;hrsold=Math.floor(e_hrsold);e_minsold=(e_hrsold-hrsold)*60;minsold=Math.floor((e_hrsold-hrsold)*60);seconds=Math.floor((e_minsold-minsold)*60);span_dt_dt.innerHTML="DIUDIU 小菜鸟已运行"+daysold+"天"+hrsold+"小时"+minsold+"分"+seconds+"秒";}s();</script></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: '6yuSDkPBguVOpM4aUQdtT8Lq-gzGzoHsz',
      appKey: '6U7kanDIFbCgrVL7XtRaaNLV',
      placeholder: '留下您的足迹',
      avatar: 'robohash',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https') {
    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>